{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_df = pd.read_csv(\"Data/preprocessed_data_SVD.csv\",header=None)\n",
    "pca_df = pd.read_csv(\"Data/preprocessed_data_PCA.csv\",header=None)\n",
    "labels_df = pd.read_csv(\"Data/labels.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels_df.iloc[:,1]\n",
    "num_lab = int(np.max(np.unique(labels))) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize PCA reduced values\n",
    "pca_df=(pca_df-pca_df.mean())/pca_df.std()\n",
    "num_dim = pca_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = to_categorical(labels, num_classes = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split PCA data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    pca_df, labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1942872, 25)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_dim = num_dim))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_lab, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kayaz\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "1457154/1457154 [==============================] - 37s 25us/step - loss: 1.9412 - acc: 0.3354\n",
      "Epoch 2/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 1.5151 - acc: 0.4688\n",
      "Epoch 3/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 1.3405 - acc: 0.5202\n",
      "Epoch 4/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 1.2291 - acc: 0.5532\n",
      "Epoch 5/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 1.1496 - acc: 0.5772\n",
      "Epoch 6/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 1.0879 - acc: 0.5957\n",
      "Epoch 7/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 1.0377 - acc: 0.6114\n",
      "Epoch 8/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.9965 - acc: 0.6243\n",
      "Epoch 9/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.9595 - acc: 0.6365\n",
      "Epoch 10/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.9283 - acc: 0.6464\n",
      "Epoch 11/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.9002 - acc: 0.6554\n",
      "Epoch 12/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.8758 - acc: 0.6634\n",
      "Epoch 13/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.8527 - acc: 0.6710\n",
      "Epoch 14/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.8313 - acc: 0.6788\n",
      "Epoch 15/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.8125 - acc: 0.6845\n",
      "Epoch 16/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.7965 - acc: 0.6904\n",
      "Epoch 17/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.7791 - acc: 0.6962\n",
      "Epoch 18/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.7647 - acc: 0.7010\n",
      "Epoch 19/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.7515 - acc: 0.7056\n",
      "Epoch 20/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.7389 - acc: 0.7098\n",
      "Epoch 21/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.7278 - acc: 0.7140\n",
      "Epoch 22/100\n",
      "1457154/1457154 [==============================] - 22s 15us/step - loss: 0.7157 - acc: 0.7183\n",
      "Epoch 23/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.7055 - acc: 0.7216\n",
      "Epoch 24/100\n",
      "1457154/1457154 [==============================] - 22s 15us/step - loss: 0.6955 - acc: 0.7250\n",
      "Epoch 25/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.6863 - acc: 0.7284\n",
      "Epoch 26/100\n",
      "1457154/1457154 [==============================] - 22s 15us/step - loss: 0.6775 - acc: 0.7318\n",
      "Epoch 27/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.6689 - acc: 0.7351\n",
      "Epoch 28/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.6612 - acc: 0.7376\n",
      "Epoch 29/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.6538 - acc: 0.7403\n",
      "Epoch 30/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.6476 - acc: 0.7426\n",
      "Epoch 31/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.6403 - acc: 0.7453\n",
      "Epoch 32/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.6334 - acc: 0.7478\n",
      "Epoch 33/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.6273 - acc: 0.7502\n",
      "Epoch 34/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.6215 - acc: 0.7521\n",
      "Epoch 35/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.6167 - acc: 0.7539\n",
      "Epoch 36/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.6107 - acc: 0.7561\n",
      "Epoch 37/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.6062 - acc: 0.7584\n",
      "Epoch 38/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.6012 - acc: 0.7597\n",
      "Epoch 39/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.5964 - acc: 0.7615\n",
      "Epoch 40/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.5916 - acc: 0.7636\n",
      "Epoch 41/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.5873 - acc: 0.7649\n",
      "Epoch 42/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.5827 - acc: 0.7666\n",
      "Epoch 43/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.5789 - acc: 0.7681\n",
      "Epoch 44/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.5753 - acc: 0.7701\n",
      "Epoch 45/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.5716 - acc: 0.7708\n",
      "Epoch 46/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.5681 - acc: 0.7726\n",
      "Epoch 47/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.5640 - acc: 0.7738\n",
      "Epoch 48/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.5612 - acc: 0.7746\n",
      "Epoch 49/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.5574 - acc: 0.7761\n",
      "Epoch 50/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.5531 - acc: 0.7780\n",
      "Epoch 51/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.5510 - acc: 0.7789\n",
      "Epoch 52/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.5482 - acc: 0.7802\n",
      "Epoch 53/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.5455 - acc: 0.7809\n",
      "Epoch 54/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.5415 - acc: 0.7823\n",
      "Epoch 55/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.5399 - acc: 0.7828\n",
      "Epoch 56/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.5367 - acc: 0.7839\n",
      "Epoch 57/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.5348 - acc: 0.7851\n",
      "Epoch 58/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.5326 - acc: 0.7855\n",
      "Epoch 59/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.5296 - acc: 0.7868\n",
      "Epoch 60/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.5264 - acc: 0.7880\n",
      "Epoch 61/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.5249 - acc: 0.7888\n",
      "Epoch 62/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.5231 - acc: 0.7896\n",
      "Epoch 63/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.5204 - acc: 0.7903\n",
      "Epoch 64/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.5185 - acc: 0.7909\n",
      "Epoch 65/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.5161 - acc: 0.7921\n",
      "Epoch 66/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.5144 - acc: 0.7926\n",
      "Epoch 67/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.5115 - acc: 0.7939\n",
      "Epoch 68/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.5101 - acc: 0.7945\n",
      "Epoch 69/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.5080 - acc: 0.7954\n",
      "Epoch 70/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.5058 - acc: 0.7958\n",
      "Epoch 71/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.5044 - acc: 0.7966\n",
      "Epoch 72/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.5018 - acc: 0.7980\n",
      "Epoch 73/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.5015 - acc: 0.7979\n",
      "Epoch 74/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.5002 - acc: 0.7985\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.4976 - acc: 0.7994\n",
      "Epoch 76/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.4961 - acc: 0.8000\n",
      "Epoch 77/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.4933 - acc: 0.8012\n",
      "Epoch 78/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.4925 - acc: 0.8010\n",
      "Epoch 79/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.4916 - acc: 0.8020\n",
      "Epoch 80/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.4896 - acc: 0.8022\n",
      "Epoch 81/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.4875 - acc: 0.8035\n",
      "Epoch 82/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.4866 - acc: 0.8038\n",
      "Epoch 83/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.4853 - acc: 0.8042\n",
      "Epoch 84/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.4839 - acc: 0.8049\n",
      "Epoch 85/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.4833 - acc: 0.8054\n",
      "Epoch 86/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.4806 - acc: 0.8063\n",
      "Epoch 87/100\n",
      "1457154/1457154 [==============================] - 22s 15us/step - loss: 0.4801 - acc: 0.8064\n",
      "Epoch 88/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.4786 - acc: 0.8071\n",
      "Epoch 89/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.4773 - acc: 0.8072\n",
      "Epoch 90/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.4761 - acc: 0.8080\n",
      "Epoch 91/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.4746 - acc: 0.8081\n",
      "Epoch 92/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.4737 - acc: 0.8090\n",
      "Epoch 93/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.4727 - acc: 0.8093\n",
      "Epoch 94/100\n",
      "1457154/1457154 [==============================] - 22s 15us/step - loss: 0.4722 - acc: 0.8098\n",
      "Epoch 95/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.4698 - acc: 0.8107\n",
      "Epoch 96/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.4685 - acc: 0.8108\n",
      "Epoch 97/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.4681 - acc: 0.8110\n",
      "Epoch 98/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.4662 - acc: 0.8117\n",
      "Epoch 99/100\n",
      "1457154/1457154 [==============================] - 21s 15us/step - loss: 0.4660 - acc: 0.8118\n",
      "Epoch 100/100\n",
      "1457154/1457154 [==============================] - 21s 14us/step - loss: 0.4650 - acc: 0.8124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x206de5d31d0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          epochs=200,\n",
    "          batch_size= 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "485718/485718 [==============================] - 4s 7us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "import pickle\n",
    "pickle.dump(model, open(\"cnn_model_100.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.30399869059071666, 0.8857402855162]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-gpu",
   "language": "python",
   "name": "keras-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
